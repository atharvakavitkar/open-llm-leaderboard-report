# Open-LLM-Leaderboard
https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard

The ðŸ¤— Open LLM Leaderboard tracks, ranks, and evaluates large language models and chatbots. It evaluates models based on benchmarks from the Eleuther AI Language Model Evaluation Harness, covering science questions, commonsense inference, multitask accuracy, and truthfulness in generating answers. The leaderboard allows community members to submit models for automated evaluation on the ðŸ¤— GPU cluster, as long as they are ðŸ¤— Transformers models with weights on the Hub. The benchmarks aim to test reasoning and general knowledge in different fields using 0-shot and few-shot settings.
